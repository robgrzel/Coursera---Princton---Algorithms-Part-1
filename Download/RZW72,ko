1
00:00:02,041 --> 00:00:07,088
자, 이제까지 quick-union 과 quick-find 알고리즘을 살펴봤습니다.

2
00:00:07,088 --> 00:00:13,034
둘 다 구현은 쉽습니다만, 아주 큰
 동적 연결성(dynamic connectivity) 문제를 해결할 순 없습니다.

3
00:00:13,034 --> 00:00:18,151
그렇다면 우린 이걸 어떻게 향상시킬 수 있을까요?
 앞으로 살펴보도록 하죠.

4
00:00:18,151 --> 00:00:23,731
아주 효과적인 개선법 중 하나는
 소위 가중치 할당 기법(weighting)입니다.

5
00:00:23,731 --> 00:00:28,764
여러분이 앞의 알고리즘들을 유심히 보다 보면
 이 방법이 떠올랐을 수도 있습니다.

6
00:00:28,764 --> 00:00:34,735
아이디어는 바로 quick-union 알고리즘을 구현할 때
 트리가 커지는 걸 회피하도록 구현하는 거죠.

7
00:00:34,735 --> 00:00:41,873
만약 규모가 큰 트리와 작은 트리를 합쳐야 한다면,
 큰 트리를 작은 트리 밑으로 넣으면 안 됩니다.

8
00:00:41,873 --> 00:00:48,184
안 그러면 아주 높이가 높은
 트리가 만들어 질 테니까요.

9
00:00:48,184 --> 00:00:54,376
그렇게 하기 위한
 비교적 간단한 방법이 있습니다.

10
00:00:54,376 --> 00:01:00,577
각 트리에 있는 요소의 수를
 계속 기록해 트리의 규모를 파악하고,

11
00:01:03,558 --> 00:01:05,049
큰 트리의 루트 아래에 작은 트리의 루트를
 연결해서 균형을 유지하도록 하는 거죠.

12
00:01:06,539 --> 00:01:12,176
그렇게 함으로써 키가 큰 트리가
 작은 트리 아래로 가는 첫 번째 상황을 피할 수 있죠.

13
00:01:12,176 --> 00:01:18,053
가중치 알고리즘에서는 항상 작은 트리가
 큰 트리의 아래로 들어가게 해야 합니다.

14
00:01:18,053 --> 00:01:27,470
어떻게 구현할 지 보도록 하죠.
 우선 데모를 보겠습니다.

15
00:01:27,470 --> 00:01:34,790
네, 다시 일반적인 시작점에서 출발하죠.
 각 요소가 각자 트리를 이룬 상태입니다.

16
00:01:35,059 --> 00:01:42,249
아이템이 두 개만 있으면 연결하면 되고요,
 이전처럼 동작합니다.

17
00:01:42,249 --> 00:01:48,725
그런데 union(3, 8)이 주어지니 이제 8로 구성된 트리와
 4와 3으로 구성된 트리를 합쳐야 하는데, 우리는 8을 자식으로 놓죠.

18
00:01:48,725 --> 00:01:56,408
인자의 순서가 무엇이든 간에
 8이 더 작은 트리니까요.

19
00:01:56,408 --> 00:02:02,368
6 과 5 는 별 문제 없죠.
 어떤게 아래로 가든지요.

20
00:02:02,368 --> 00:02:09,710
union (9, 4)네요. 여기서 9가 더 작고, 4가 속한 트리가
 더 큽니다.그래서 9가 4 아래로 갑니다.

21
00:02:09,710 --> 00:02:20,136
union (2, 1)은 별 것 없고요. union(5, 0)에서,
 5 측이 더 큰 트리이므로 0이 5가 있는

22
00:02:20,136 --> 00:02:33,812
큰 트리의 루트의 아래, 즉 6 아래로 갑니다.
 union(7, 2)네요. 2가 더 큰 트리이므로 7 이 2 밑으로 가죠.

23
00:02:33,812 --> 00:02:46,129
union(6, 1)죠. 이건 같은 크기라
 한 쪽이 다른 쪽으로 가면 됩니다.

24
00:02:46,129 --> 00:02:59,272
union(7, 3)네요. 3이
 더 작은 측의 트리니 아래로 갑니다.

25
00:02:59,272 --> 00:03:08,686
자, 가중치 알고리즘에서는
 항상 작은 트리가 아래로 가게 됩니다.

26
00:03:08,686 --> 00:03:15,571
이제 다시 모든 요소들이 속한 하나의 트리를 구성했습니다.
 그러나 이번엔 어떤 요소도

27
00:03:15,571 --> 00:03:21,267
루트로부터 아주 멀리 떨어져 있지
 않음을 보장할 수 있죠.

28
00:03:21,267 --> 00:03:27,980
좀 있다가 자세히 살펴봅시다. 다음 예제는
 가중치에 따른 quick union 알고리즘의 동작을 보여줍니다.

29
00:03:27,980 --> 00:03:35,236
완전히 같은 union 연산을 처리했는데, 가중치를 준
 quick union은 언제나 작은 트리를 큰 트리 아래에 넣었습니다.

30
00:03:35,236 --> 00:03:42,939
100 개의 원소와 88번의 union 연산을
 한 것이고요. 상단을 보면

31
00:03:42,939 --> 00:03:49,768
큰 트리가 있는데, 이를 구성하는 작은 트리나
 노드들이 루트로부터 꽤 떨어져 있습니다.

32
00:03:49,768 --> 00:03:55,908
하단에는 가중치 알고리즘으로 인해
 모든 노드가 루트와의 거리가 4 이내입니다.

33
00:03:55,908 --> 00:04:01,207
루트로 가는 평균 거리는 훨씬, 훨씬 짧습니다.

34
00:04:01,207 --> 00:04:06,557
이제 Java 구현을 살펴봅시다. 그 뒤에
 정량적인 정보에 대해 살펴보죠.

35
00:04:06,557 --> 00:04:12,286
자, 앞서 사용한 같은 자료구조를 사용할
 거지만, 추가적인 배열 sz[]을 필요로 합니다.

36
00:04:12,286 --> 00:04:17,569
이 새 배열은 각 요소 i에 대해서, i를
 루트로 하여 만든 트리의 요소 수를 기록합니다.

37
00:04:17,569 --> 00:04:22,971
이 배열은 union 연산을 하는
 과정에서 갱신될 것이고요.

38
00:04:22,971 --> 00:04:28,589
find 연산의 구현은 quick union과 동일합니다.
 주어진 두 요소의 루트가 같은지를 확인합니다.

39
00:04:28,589 --> 00:04:34,009
union 연산의 구현에서는 앞에서 말한 크기를
 확인하도록 코드를 변경할 겁니다.

40
00:04:34,009 --> 00:04:40,118
그리고, 경우를 나누어, 작은 트리의 루트가
 큰 트리의 루트 아래에 가도록 연결합니다.

41
00:04:40,118 --> 00:04:46,049
배열 id[]에 저장된 링크 정보를 수정하고 나서, 배열 sz[] 또한 변경합니다.

42
00:04:46,049 --> 00:04:52,241
즉, id[i]가 j와 같도록 해서 i가 j의 자식이 되게 하면,
 j의 크기 sz[j]를 sz[i]만큼 키울 필요가 있습니다.

43
00:04:52,241 --> 00:04:58,495
만약 j가 i의 자식이 되어야 한다면
 i의 크기 sz[i]를 j의 크기 sz[j]만큼 키워야겠죠.

44
00:04:58,495 --> 00:05:04,849
그래서 quick union 구현의 전체 코드가 
 흰 색으로 표시되어 있습니다.

45
00:05:04,849 --> 00:05:12,424
코드량은 별로 없지만, 훨씬 성능이 뛰어납니다.

46
00:05:12,424 --> 00:05:19,194
사실 수행시간을 수학적으로 분석해보면,
 정의한 연산이 트리에 있는 노드들이

47
00:05:19,194 --> 00:05:25,225
얼마나 멀리 떨어져 있는지에 비례해
시간이 걸림을 보일 수 있습니다.

48
00:05:25,225 --> 00:05:31,445
그러나 트리 내의 어떤 노드 x라도 최대 깊이가

49
00:05:31,445 --> 00:05:37,989
밑이 2인 로그 N이라는 걸 보여줄 수 있죠.

50
00:05:37,989 --> 00:05:43,974
lg는 밑이 2인 로그를 가리키기로 합시다.
 그래서 N이 만약 1000 이라면

51
00:05:43,974 --> 00:05:49,246
최대 높이는 10이 될 거고, N이 만약 백만이라면
 20이 되죠. 만약 N 이 10억이라면 30이 됩니다.

52
00:05:49,246 --> 00:05:55,745
이 값은 N에 비해 아주 작은 숫자죠.
 그럼 이제 그 증명을 보죠.

53
00:05:55,745 --> 00:06:02,046
이 강의에선 이처럼 중요한 명제에 대해서는
 다소 수학적인 증명을 할겁니다.

54
00:06:02,046 --> 00:06:07,981
그럼 어떤 노드 x 의 깊이가 기껏해야
 lg N이라는 게 어째서 사실일까요?

55
00:06:07,981 --> 00:06:13,850
이걸 이해하는 데 있어 핵심은 어떤 노드의
 깊이가 언제 증가하는지를 살펴보는 것입니다.

56
00:06:13,850 --> 00:06:21,347
언제 트리에서 더 아래로 내려갑니까?

57
00:06:21,347 --> 00:06:29,697
자, 그림에서 T1이라 표기된 트리가 다른 트리,
 그림에선 T2에 합쳐지면, x의 깊이는 1만큼 증가합니다.

58
00:06:29,697 --> 00:06:37,835
그리고, 이와 같은 성질은 T2가 T1보다 크기 측면에서

59
00:06:37,835 --> 00:06:45,331
크거나 같을때에만 성립합니다.

60
00:06:45,331 --> 00:06:52,662
즉, x의 깊이가 증가할 때 그 트리는 적어도
 2배가 되죠. 이게 핵심인데요.

61
00:06:52,662 --> 00:06:58,305
x 가 속한 트리의 크기가 최대 lg N 배만큼
 커지는 걸 의미하기 때문이죠.

62
00:06:58,305 --> 00:07:05,205
왜냐하면 1 부터 시작해 lg N 번만큼 두 배를 하면
 N이니까, 이 트리엔 최대 N 개의 노드만 있게 됩니다.

63
00:07:05,205 --> 00:07:11,631
이것이 어떤 노드 x 의 깊이도 최대 ln N 임을
 보이는 증명의 스케치였습니다.

64
00:07:11,631 --> 00:07:18,605
증명한 명제는 알고리즘의 성능에
 막대한 영향을 미칩니다.

65
00:07:18,605 --> 00:07:24,548
초기화에서 매번 N에 비례해
 시간이 걸리는 것이,

66
00:07:24,548 --> 00:07:31,010
이젠 union 연산과 connected (또는 find)
 연산은 ln N 에 비례합니다.

67
00:07:31,010 --> 00:07:37,477
이 알고리즘은 확장성이 있지요.
 N이 백만에서 10억으로 증가하면

68
00:07:37,477 --> 00:07:43,668
비용은 20 에서 30 이 되는데,
 이건 꽤 수용할 만 합니다.

69
00:07:43,668 --> 00:07:50,089
자, 매우 쉬운 구현이었는데요,
이제 그만할 수도 있지만

70
00:07:50,089 --> 00:07:57,004
알고리즘 설계 과정을 살펴보았고,
 얼마만큼의 성능인지도 보았으므로

71
00:07:57,004 --> 00:08:02,075
더욱더 향상가능한지를 살펴봅시다.
 사실 이 경우는 성능을 더욱더 향상시키는 게 매우 쉽습니다.

72
00:08:02,075 --> 00:08:09,072
향상시키는 방법은 경로 압축(path compression)이라
 불리는 아이디어입니다.

73
00:08:09,072 --> 00:08:17,066
기존 방법에서는 우리가 주어진 노드가
 속한 루트 p를 찾으려 할 때

74
00:08:17,066 --> 00:08:24,361
노드 p에서 루트로의 경로에 있는
 모든 노드를 건드리게 됩니다.

75
00:08:24,568 --> 00:08:30,422
이 아이디어에서는 그러지 말고 각 노드가 
 루트를 가리키게 합니다.

76
00:08:30,422 --> 00:08:37,299
그렇게 하면 안 될 이유가 없죠.
 p 의 루트를 찾으려고 할 때,

77
00:08:37,299 --> 00:08:43,580
루트를 찾은 뒤로 돌아가 
 경로에 있는 모든 노드가

78
00:08:43,580 --> 00:08:51,046
루트를 가리키게 합니다.
이건 추가적인 상수 시간이 걸릴 겁니다.

79
00:08:51,046 --> 00:08:57,088
일단 루트를 찾기 위해 경로를 거슬러 간 바 있죠.
이제 트리를 평평하게 하기 위해

80
00:08:57,088 --> 00:09:03,099
다시 거슬러 올라갈겁니다.
그렇게 안 할 이유가 없어서죠.

81
00:09:03,099 --> 00:09:10,016
놀랍게도, 단 한 줄의 코드로 트리를 평평하게 할 수 있습니다.

82
00:09:10,016 --> 00:09:15,058
사실, 코드 수를 줄이기 위해 간단히 변형해서
 경로 상의 각 노드들이

83
00:09:15,058 --> 00:09:19,885
원 트리 상에서의 할아버지 노드를 가리키게 하였습니다.

84
00:09:21,000 --> 00:09:26,077
완전히 평평하게 만들지는 않아 꼭 좋은 건 아니지만
 실용적 측면에서는 대략 좋을 겁니다.

85
00:09:26,077 --> 00:09:32,555
그래서 한 줄의 코드로 트리를 거의 평평하게
유지 할 수 있게 되었습니다.

86
00:09:32,828 --> 00:09:41,987
이 알고리즘은 가중치 할당 기법이
 논의된 뒤로 꽤 초기에 발견되었는데

87
00:09:41,987 --> 00:09:49,588
강의 범위를 벗어나지만 분석하기에
 꽤 매력적인 것으로 판명되었습니다.

88
00:09:49,588 --> 00:09:55,749
예시를 통해 그 점을 보여주려는데, 이를 통해
 이 간단한 알고리즘이 얼마나 복잡도 분석에서 흥미로운지 봅시다.

89
00:09:55,749 --> 00:10:02,203
이 명제는 John E. Hopcroft (코넬대 교수)-Jeffrey D. Ullman(스탠퍼드대 교수)과
 Robert E. Tarjan (프린스턴대 교수)에 의해 증명되었는데,

90
00:10:02,203 --> 00:10:07,792
N 개의 객체(=노드)가 있을 때,
 M 번의 union 연산과 find 연산이 어떤 순서로 실행되든

91
00:10:07,792 --> 00:10:16,014
기껏해야 c(N+M lg star N) 번 배열에 접근한다는 것입니다.

92
00:10:16,248 --> 00:10:22,067
여기서 로그 스타 N (즉 lg* N)은 재밌는 함수인데요. N이라는 숫자를
 1로 바꾸기 위해 lg N을 취해야 하는 횟수를 나타내는 함수입니다.

93
00:10:22,067 --> 00:10:28,061
이 함수를 반복 로그 함수(iterate log function)이라 부릅니다.

94
00:10:28,061 --> 00:10:36,126
그리고 N=2^(65536) (^는 지수승 기호)에 대한 반복 로그 함수값은 5이므로 
실세계에선 그보다 작은 수로 생각하면 좋습니다.

95
00:10:36,126 --> 00:10:42,528
즉, 경로 압축이 적용된 가중치 기반 quick union의 수행시간은

96
00:10:42,784 --> 00:10:49,990
실세계에서는 선형함수에 가깝습니다. 
 사실 이 결과는 Ackermann 함수 α(M, N)로 불리는 함수로

97
00:10:49,990 --> 00:10:56,504
더 개선될 수 있습니다.
 이 함수는 로그 스타 함수보다도 훨씬

98
00:10:56,504 --> 00:11:03,611
천천히 증가합니다.
<i>이 함수의 또 다른 면은</i>

99
00:11:03,611 --> 00:11:09,813
M에 대한 느린 증가 함수에 N을 곱한 함수보다는
 선형 함수, 즉 N에 비례하는 함수에 '근접한' 실행 시간을 가진 것처럼 동작합니다.

100
00:11:09,813 --> 00:11:15,925
그러면 선형 함수를 따르는 실행 시간을 가진 더 단순한 알고리즘이 있을까요?

101
00:11:15,925 --> 00:11:22,008
오랫동안 사람들이 찾고자 노력했지만, 
 이 경우에서는 실제로는

102
00:11:22,008 --> 00:11:27,700
그러한 알고리즘이 없다는 것을 증명할 수 있습니다.

103
00:11:27,700 --> 00:11:32,502
우리가 사용하는 알고리즘의 이면에는
 아주 많은 이론이 깔려있습니다.

104
00:11:32,502 --> 00:11:38,022
그래서 그 이론을 아는 것은 중요할 뿐만 아니라,
 우리가 현실에서 어떤 알고리즘을

105
00:11:38,022 --> 00:11:43,480
사용할 지 결정할 때에도 사용 가능하지만, 
 보다 더 나은 알고리즘을 찾기 위해

106
00:11:43,480 --> 00:11:48,796
우리의 노력을 어디에 집중할 지를 결정할 때도 도움을 줍니다.
 Union find 문제에서는

107
00:11:48,796 --> 00:11:54,181
선형 시간 알고리즘이 없다는 이 놀라운 사실은
 최종적으로 Michael L. Fredman (Rutgers 대 교수)과 Michael E. Saks (Rutgers 대 교수)에 의해 증명되었습니다.

108
00:11:54,181 --> 00:12:00,293
그러나 경로 압축이 적용된 가중치 기반의 quick union 은

109
00:12:00,293 --> 00:12:05,844
현실에서 큰 문제에 적용하기에 충분합니다.

110
00:12:05,844 --> 00:12:11,713
자 이제 동적 연결설 문제를 푸는 알고리즘들에 대해 요약해 보죠.

111
00:12:11,713 --> 00:12:17,128
경로 압축이 적용된 가중치 기반의 quick union을 통해 
 다른 방법으로는 해결될 수 없었던

112
00:12:17,128 --> 00:12:23,109
문제를 풀 수 있었습니다. 
 예를 들어 십억 개의 연산과

113
00:12:23,109 --> 00:12:28,845
십억 개의 객체가 있었다면,
 제가 전에 말했듯이 30 년이 걸렸을 지도 모릅니다.

114
00:12:28,845 --> 00:12:34,212
우리는 그걸 6초 내에 할 수 있죠. 
 이로부터 가장 중요한 걸 알 수 있는데,

115
00:12:34,212 --> 00:12:40,012
알고리즘 설계는 문제에 대한 해법을 가능케 한다는 것입니다.

116
00:12:40,012 --> 00:12:45,529
빠른 컴퓨터는 그리 많은 도움이 되지 않습니다.
 수백만 개의 수퍼 컴퓨터를 사용할 수 있을 지라도

117
00:12:45,529 --> 00:12:51,165
30년 대신 6년 정도 또는 
한 두달이 걸리게 되겠지만

118
00:12:51,165 --> 00:13:02,056
빠른 알고리즘을 이용하면 여러분의 PC 로도 
단지 수 초내에 가능합니다.