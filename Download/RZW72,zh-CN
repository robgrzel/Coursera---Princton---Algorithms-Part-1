1
00:00:02,041 --> 00:00:07,088
好，我们已经看了快速合并和快速查找算法，两种算法

2
00:00:07,088 --> 00:00:13,034
都很容易实现，但是不支持巨大的动态连通性问题

3
00:00:13,034 --> 00:00:18,151
那么，我们该怎么改进呢？下面我们就来讲这个问题

4
00:00:18,151 --> 00:00:23,731
一种非常有效的改进方法，叫做带权。也许

5
00:00:23,731 --> 00:00:28,764
我们在讲这两个算法的时候你已经想到了。这个改进的想法是

6
00:00:28,764 --> 00:00:34,735
在实现快速合并算法的时候执行一些操作避免得到很高的树

7
00:00:34,735 --> 00:00:41,873
如果一棵大树和一棵小树合并，你会想试着

8
00:00:41,873 --> 00:00:48,184
避免将大树放在下面，那将会导致更高的树

9
00:00:48,184 --> 00:00:54,376
这个加权操作实现起来也相对容易。我们会跟踪

10
00:00:54,376 --> 00:01:00,577
每棵树中对象的个数，然后

11
00:01:03,558 --> 00:01:05,049
我们通过确保将小树的根节点作为大树的根节点的子节点以维持平衡

12
00:01:06,539 --> 00:01:12,176
所以，我们避免左图中将大的树放在下面的情况

13
00:01:12,176 --> 00:01:18,053
在带权算法中，我们总是将小的树放在下面

14
00:01:18,053 --> 00:01:27,470
我们看应该如何实现它。首先我们来看演示。好的，我们又

15
00:01:27,470 --> 00:01:34,790
从我们通常的位置开始，每个对象在自己的树中

16
00:01:35,059 --> 00:01:42,249
如果只需要连接两个对象，和之前的算法是一样的

17
00:01:42,249 --> 00:01:48,725
但是现在我们要将8与4和3合并，我们把8作为子节点

18
00:01:48,725 --> 00:01:56,408
而不看参数的顺序如何，因为8是更小的树

19
00:01:56,408 --> 00:02:02,368
6和5不影响，哪个在下面都无所谓。9和4

20
00:02:02,368 --> 00:02:09,710
9那棵树小，4那棵树大。所以9在下面

21
00:02:09,710 --> 00:02:20,136
2和1，5和0。5在大树中

22
00:02:20,136 --> 00:02:33,812
所以0到下面。7和2，2在大树中

23
00:02:33,812 --> 00:02:46,129
所以7到下面。6和1，树的大小相同。7和3

24
00:02:46,129 --> 00:02:59,272
3在小树中所以3到下面。所以，带权算法总是

25
00:02:59,272 --> 00:03:08,686
确保小树到下面。我们又得到了一棵包含所有对象的树

26
00:03:08,686 --> 00:03:15,571
但是这次，我们有一些约束保证所有的对象不会离根节点太远

27
00:03:15,571 --> 00:03:21,267
我们一会明确地分析一下这个性质

28
00:03:21,267 --> 00:03:27,980
这个例子展示了对于同一组合并命令使用带权快速合并算法的效果

29
00:03:27,980 --> 00:03:35,236
我们总是将小树放在下面

30
00:03:35,236 --> 00:03:42,939
100个对象，88个合并操作。可以看到上面无权算法

31
00:03:42,939 --> 00:03:49,768
大树中有些节点离根节点有些远。下面

32
00:03:49,768 --> 00:03:55,908
使用带权算法所有节点距离根节点都在4以内

33
00:03:55,908 --> 00:04:01,207
对象与根节点的平均距离小多了

34
00:04:01,207 --> 00:04:06,557
我们来看一下Java实现，然后我们做一些深入的定量分析

35
00:04:06,557 --> 00:04:12,286
我们在之前相同数据结构基础上，需要一个额外的数组

36
00:04:12,286 --> 00:04:17,569
对于每个对象，给出以该对象为根节点的树中的对象个数

37
00:04:17,569 --> 00:04:22,971
在合并操作中我们会维护这个数组。查找操作的实现

38
00:04:22,971 --> 00:04:28,589
与快速合并算法中的相同，只需要检查根节点是否相同

39
00:04:28,589 --> 00:04:34,009
对于合并操作的实现，我们修改代码使它检查树的大小

40
00:04:34,009 --> 00:04:40,118
然后将小树的根节点连接到大树的根节点上

41
00:04:40,118 --> 00:04:46,049
在改变id记录值之后，我们还要改变大小数组。如果把i变为j的子节点

42
00:04:46,049 --> 00:04:52,241
我们需要给j的树的大小加上i的树的大小

43
00:04:52,241 --> 00:04:58,495
反之，我们需要给i的树的大小加上j的树的大小

44
00:04:58,495 --> 00:05:04,849
那么，白色背景的代码就是实现快速合并的完整代码了

45
00:05:04,849 --> 00:05:12,424
并没有增加很多代码，但是性能有了很大提高。实际上我们能

46
00:05:12,424 --> 00:05:19,194
从数学上分析运行时间并且证明我们定义的操作需要花费

47
00:05:19,194 --> 00:05:25,225
的时间与节点在树中的深度成正比

48
00:05:25,225 --> 00:05:31,445
我们可以证明树中任意节点的深度

49
00:05:31,445 --> 00:05:37,989
上限是以2为底N的对数。我们使用

50
00:05:37,989 --> 00:05:43,974
lg表示以2为底的对数。如果N=1000

51
00:05:43,974 --> 00:05:49,246
对数是10。N是1百万，对数是20。N是10亿

52
00:05:49,246 --> 00:05:55,745
对数是30。和N相比对数值非常小。我们来看它的证明

53
00:05:55,745 --> 00:06:02,046
这门课中对于这种至关重要的结论我们会做数学证明

54
00:06:02,046 --> 00:06:07,981
那么为什么任意节点x的深度最多是N以2为底的对数呢？

55
00:06:07,981 --> 00:06:13,850
理解这个问题的关键在于观察节点的深度到底是在何时增加的

56
00:06:13,850 --> 00:06:21,347
何时它在树中变得更深？

57
00:06:21,347 --> 00:06:29,697
当x所在的树，即图中的T1，与另一棵树，即图中的T2，合并的时候x的深度加1

58
00:06:29,697 --> 00:06:37,835
好，之前我们说过只有在T2的大小

59
00:06:37,835 --> 00:06:45,331
T2的大小大于等于T1的大小时才会发生这种情况
所以当x深度增加时

60
00:06:45,331 --> 00:06:52,662
树的大小至少翻倍。这很关键，因为这意味着

61
00:06:52,662 --> 00:06:58,305
包含x的树的大小最多可以翻N次倍因为如果从1开始

62
00:06:58,305 --> 00:07:05,205
翻倍lg N次，就会得到N，而最后树中总共只有N个节点

63
00:07:05,205 --> 00:07:11,631
这就是任意节点x的深度最多是N以2为底的对数的粗略证明

64
00:07:11,631 --> 00:07:18,605
这对于这个算法的性能有着巨大的影响

65
00:07:18,605 --> 00:07:24,548
现在，除了初始化总是需要正比于N的时间，合并和

66
00:07:24,548 --> 00:07:31,010
“是否连接”或查询操作需要的时间都是正比于N以2为底的对数

67
00:07:31,010 --> 00:07:37,477
这个算法能成比例适应大规模问题。当N从1百万变为10亿

68
00:07:37,477 --> 00:07:43,668
花费的时间从20变为30，这就比较能接受了。实现起来也很容易

69
00:07:43,668 --> 00:07:50,089
我们本可以到此为止了，但是通常算法设计中

70
00:07:50,089 --> 00:07:57,004
我们理解了如何获取性能，我们就会

71
00:07:57,004 --> 00:08:02,075
进一步看是否能够再改进一些。这个例子中

72
00:08:02,075 --> 00:08:09,072
很容易再多改进一些。这个想法就是路径压缩

73
00:08:09,072 --> 00:08:17,066
当我们试图寻找包含给定节点的树的根节点时

74
00:08:17,066 --> 00:08:24,361
我们需要访问从该节点到根节点路径上的每个节点

75
00:08:24,568 --> 00:08:30,422
与此同时我们可以将每个节点都指向根节点

76
00:08:30,422 --> 00:08:37,299
为什么不呢？所以当我们找到P的根节点之后

77
00:08:37,299 --> 00:08:43,580
可以回过头来将路径上每个节点都指向根节点

78
00:08:43,580 --> 00:08:51,046
这需要常数的额外代价

79
00:08:51,046 --> 00:08:57,088
我们回溯一次路径找到根节点，然后再回溯一次将树展平

80
00:08:57,088 --> 00:09:03,099
我们为什么不这么做呢？令人惊奇的是

81
00:09:03,099 --> 00:09:10,016
我们只需要添加一行代码就能将树展平。实际上，为了只添加一行代码

82
00:09:10,016 --> 00:09:15,058
我们稍做了一点改变：我们将路径上每个节点指向

83
00:09:15,058 --> 00:09:19,885
它在路径上的祖父节点。这种实现不如完全展平好

84
00:09:21,000 --> 00:09:26,077
实际应用中两者差不多一样好

85
00:09:26,077 --> 00:09:32,555
所以，我们用了一行代码，就让树基本完全展平了

86
00:09:32,828 --> 00:09:41,987
人们在想出带权之后很快就发现这个算法

87
00:09:41,987 --> 00:09:49,588
而要分析这个算法则超出了我们这门课的范围

88
00:09:49,588 --> 00:09:55,749
但我们这个例子很好地说明了即使简单的算法也可以有很有意思而且复杂的分析

89
00:09:55,749 --> 00:10:02,203
Hopcroft Ulman和Tarjan证明了如果

90
00:10:02,203 --> 00:10:07,792
有N个对象，M个合并与查找操作的任意序列，需要访问数组

91
00:10:07,792 --> 00:10:16,014
最多c(N + M lg* N)次。lg* N是个挺有意思的函数

92
00:10:16,248 --> 00:10:22,067
它是使N变为1需要取对数的次数

93
00:10:22,067 --> 00:10:28,061
它叫做迭代对数函数。在真实世界中

94
00:10:28,061 --> 00:10:36,126
可以认为是一个小于5的数，因为lg*（2^65536）=5

95
00:10:36,126 --> 00:10:42,528
所以，这说明带路径压缩的带权快速合并算法

96
00:10:42,784 --> 00:10:49,990
在真实世界中的时间复杂度是线性的，而实际上可以改进到

97
00:10:49,990 --> 00:10:56,504
一个更有意思的函数，Ackermann函数，这个函数增长速度

98
00:10:56,504 --> 00:11:03,611
比 lg* 还慢。另外一点要说明的是看起来<i></i>

99
00:11:03,611 --> 00:11:09,813
这个算法的时间复杂度已经非常接近与N成正比的线性了

100
00:11:09,813 --> 00:11:15,925
它与N乘一个关于N的增长非常缓慢的函数成正比。那么是否存在一个简单的算法

101
00:11:15,925 --> 00:11:22,008
其时间复杂度就是线性的呢？人们找了很久，实际上最后

102
00:11:22,008 --> 00:11:27,700
证明了这样的算法是不存在的。所以

103
00:11:27,700 --> 00:11:32,502
在我们使用的算法背后有着很多的理论工作。了解这些理论

104
00:11:32,502 --> 00:11:38,022
对我们来说是很重要的，它可以帮助我们

105
00:11:38,022 --> 00:11:43,480
在实际应用中选择算法，以及告诉我们应该在何处下功夫

106
00:11:43,480 --> 00:11:48,796
寻找更好的算法。并查集问题不存在线性时间算法

107
00:11:48,796 --> 00:11:54,181
这个精妙的结论最终是Friedman与Sachs证明的

108
00:11:54,181 --> 00:12:00,293
而在应用中，带压缩路径的带权快速合并算法

109
00:12:00,293 --> 00:12:05,844
已经足够接近线性算法了，使得我们可以求解巨大的问题

110
00:12:05,844 --> 00:12:11,713
好，我们总结一下求解动态连通性问题的算法

111
00:12:11,713 --> 00:12:17,128
使用带路径压缩带权快速合并算法，我们能够解决其他算法不能解决的问题

112
00:12:17,128 --> 00:12:23,109
例如，我之前说过如果有10亿个操作

113
00:12:23,109 --> 00:12:28,845
和10亿个对象可能需要计算30年。我们现在能在

114
00:12:28,845 --> 00:12:34,212
6秒内完成。需要认识到的更重要的是

115
00:12:34,212 --> 00:12:40,012
是算法设计使得求解大规模问题成为可能。更快的计算机

116
00:12:40,012 --> 00:12:45,529
并没有起很大作用。你可以投资上百万建造超级计算机，可能

117
00:12:45,529 --> 00:12:51,165
你不需要花30年而是6年来完成，或者两个月，但是

118
00:12:51,165 --> 00:13:02,056
使用快速的算法，你可以在你自己的家用电脑上用几秒钟完成